---
title: llm.v1
description: API Specification for the llm.v1 package.
---

<a name="output-proto"></a><p align="right"><a href="#top">Top</a></p>

<!-- begin services -->

<!-- begin services -->



<a name="llm-v1-Output"></a>

### Output

Output represents a single output from a generation, including the content and any associated rating.




| Field | Type | Description |
| ----- | ---- | ----------- |
| id |string|  Unique identifier for the output.  |
| content |string|  The actual content of the output, e.g., text generated by the model.  |
| rating |[OutputRating](#llm-v1-OutputRating)|  Associated rating for this output, if available.  |




 <!-- end nested messages -->

 <!-- end nested enums -->




<a name="llm-v1-OutputRating"></a>

### OutputRating

OutputRating represents a rating or evaluation of an output, including the score and details about the rater.




| Field | Type | Description |
| ----- | ---- | ----------- |
| score |float|  Numeric score representing the quality or other rating dimension.  |
| rater |[Rater](./prompt.md#llm-v1-Rater)|  Details about the rater, either human or model-based.  |




 <!-- end nested messages -->

 <!-- end nested enums -->


 <!-- end messages -->

<!-- begin file-level enums -->
 <!-- end file-level enums -->

<!-- begin file-level extensions -->
 <!-- end file-level extensions -->

